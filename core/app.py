import streamlit as st
from decouple import config
import torch
from dotenv import load_dotenv
from langchain.prompts import ChatPromptTemplate
from langchain_groq import ChatGroq
from langchain.chains import create_retrieval_chain
from langchain.retrievers.self_query.base import SelfQueryRetriever
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.chains.query_constructor.schema import AttributeInfo
from langchain.agents import create_tool_calling_agent
from langchain_community.tools import BraveSearch
from langchain_experimental.utilities import PythonREPL
from langchain_community.utilities import StackExchangeAPIWrapper
from langchain.agents import AgentExecutor
from langchain_core.tools import Tool

load_dotenv()

EMBEDDINGS_MODEL = "sentence-transformers/all-mpnet-base-v2"
LLM_MODEL = "deepseek-r1-distill-llama-70b"

device = "cuda" if torch.cuda.is_available() else "cpu"
embeddings = HuggingFaceEmbeddings(
    model_name=EMBEDDINGS_MODEL,
    model_kwargs={"device": device},
    encode_kwargs={"normalize_embeddings": True},
)
chroma = Chroma(
    persist_directory="./chroma_db",
    embedding_function=embeddings,
    collection_name="code_collection",
)

llm = ChatGroq(model_name=LLM_MODEL)

metadata_info = [
    AttributeInfo(
        name="source",
        description="Caminho relativo do arquivo a partir do diret√≥rio base",
        type="string",
    ),
    AttributeInfo(
        name="ext",
        description="Extens√£o do arquivo sem o ponto (por exemplo: 'py', 'js', 'md')",
        type="string",
    ),
    AttributeInfo(
        name="full_path",
        description="Caminho completo do arquivo no sistema",
        type="string",
    ),
    AttributeInfo(
        name="file_size",
        description="Tamanho do conte√∫do do arquivo em n√∫mero de caracteres",
        type="integer",
    ),
    AttributeInfo(
        name="file_type",
        description="Tipo do arquivo, como 'code', 'document' ou 'data', conforme definido no mapeamento",
        type="string",
    ),
    AttributeInfo(
        name="language",
        description="Linguagem do c√≥digo ou do documento (por exemplo: 'python', 'javascript', 'markdown')",
        type="string",
    ),
    AttributeInfo(
        name="is_chunk",
        description="Indica se o documento √© um chunk do arquivo original (True ou False)",
        type="boolean",
    ),
]


retriever = SelfQueryRetriever.from_llm(
    llm, chroma, "Django/React app codes", metadata_info, verbose=True
)

python_repl = Tool(
    name="python_repl",
    description="Utilize para validar hip√≥teses, executar pequenos trechos de c√≥digo Python, verificar rapidamente resultados de algoritmos ou c√°lculos e garantir que a resposta t√©cnica esteja correta antes de fornec√™-la ao usu√°rio.",
    func=PythonREPL().run,
    verbose=True,
)

retriever_tool = Tool(
    name="retriever_tool",
    description="Use essa ferramenta para buscar informa√ß√µes espec√≠ficas dentro do contexto completo dos arquivos do projeto, incluindo Django, React, Docker, bancos de dados, testes e outras tecnologias associadas. Ideal para entender estruturas, padr√µes de projeto, exemplos pr√°ticos e para esclarecer d√∫vidas t√©cnicas sobre o c√≥digo existente.",
    func=lambda query: "\n".join(doc.page_content for doc in retriever.invoke(query)),
    verbose=True,
)

brave_search = BraveSearch.from_api_key(
    api_key=config("BRAVE_API_KEY"), search_kwargs={"count": 3}
)

brave_tool = Tool(
    name="brave_tool",
    description="Utilize essa ferramenta para validar informa√ß√µes diretamente da internet, como corre√ß√µes de bugs, documenta√ß√£o atualizada, exemplos de uso ou quaisquer d√∫vidas gerais n√£o cobertas pelas outras ferramentas.",
    func=lambda query: brave_search.run(query),
    verbose=True,
)

stackexchange = StackExchangeAPIWrapper()

stackexchange_tool = Tool(
    name="stackexchange_tool",
    description="Utilize essa ferramenta para validar informa√ß√µes diretamente da resposta de outras pessoas, como corre√ß√µes de bugs, documenta√ß√£o atualizada, exemplos de uso ou quaisquer d√∫vidas gerais n√£o cobertas pelas outras ferramentas.",
    func=lambda query: stackexchange.run(query),
    verbose=True,
)

agent_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """Voc√™ √© Pakkun, um assistente especialista em desenvolvimento de software, dedicado a apoiar desenvolvedores experientes e iniciantes em seus desafios di√°rios com Django, React e tecnologias relacionadas, incluindo Docker, bancos de dados, testes unit√°rios, entre outras. Seu objetivo √© fornecer assist√™ncia personalizada e amig√°vel, utilizando seu profundo conhecimento dos c√≥digos do projeto atual.

Voc√™ tem acesso ao contexto completo dos arquivos de c√≥digo do projeto atrav√©s da ferramenta \"retriever_tool\", podendo recuperar informa√ß√µes detalhadas sobre a estrutura, l√≥gica, padr√µes utilizados e demais caracter√≠sticas espec√≠ficas do c√≥digo indexado. Utilize esse recurso para consultar informa√ß√µes sempre que necess√°rio.

Para informa√ß√µes adicionais atualizadas da internet, como corre√ß√µes de bugs, documenta√ß√µes recentes ou exemplos de uso externos, utilize a ferramenta \"brave_tool\".

Para solucionar problemas t√©cnicos comuns ou buscar exemplos pr√°ticos resolvidos pela comunidade t√©cnica, especialmente relacionados ao StackOverflow e outros sites da rede StackExchange, utilize a ferramenta \"stackexchange_tool\".

Sempre que mencionar trechos espec√≠ficos do c√≥digo, indique claramente o caminho completo para o arquivo correspondente.

Caso precise validar hip√≥teses ou testar trechos de c√≥digo, voc√™ pode executar c√≥digo Python diretamente utilizando a ferramenta \"python_repl\".

Sempre que houver d√∫vidas ou ambiguidades nas solicita√ß√µes do usu√°rio, fa√ßa perguntas proativas para esclarecer exatamente o que √© esperado antes de prosseguir com a resposta ou realizar testes.

Comunica√ß√£o:
- Adote um estilo amig√°vel, claro e pr√≥ximo, evitando excesso de formalidade.
- Explique conceitos t√©cnicos utilizando analogias ou exemplos simples e cotidianos sempre que poss√≠vel.
- Oriente claramente o usu√°rio sobre as decis√µes t√©cnicas tomadas e os motivos dessas escolhas.

Limita√ß√µes:
- Sua an√°lise √© baseada principalmente nos arquivos e c√≥digos do projeto indexados e na pesquisa direta via \"brave_tool\" e \"stackexchange_tool\" quando necess√°rio.
- Ao testar hip√≥teses com a ferramenta Python, certifique-se de manter testes breves e focados, garantindo efici√™ncia e clareza nos resultados obtidos.

Lembre-se: voc√™ √© um aliado pr√≥ximo do usu√°rio, oferecendo assist√™ncia precisa, clara e emp√°tica, sempre respeitando o contexto t√©cnico espec√≠fico de cada solicita√ß√£o.""",
        ),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ]
)


agent = create_tool_calling_agent(
    llm, [python_repl, retriever_tool, brave_tool, stackexchange_tool], agent_prompt
)
agent_executor = AgentExecutor(
    agent=agent, tools=[python_repl, retriever_tool, brave_tool, stackexchange_tool]
)

st.set_page_config("Pakkun - Assistente de C√≥digo", "üêï", "centered")

with st.sidebar:
    st.title("üêï Pakkun")
    st.markdown(
        """
        ### Como usar:
        - Perguntas espec√≠ficas sobre c√≥digo indexado
        - Explica√ß√µes sobre c√≥digo
        - Recomenda√ß√µes e boas pr√°ticas
    """
    )
    if st.button("Limpar conversa"):
        st.session_state.clear()
        st.rerun()

if "chat_history" not in st.session_state:
    st.session_state.chat_history = [
        {
            "role": "assistant",
            "content": """
        Oi! Sou o Pakkun, como posso ajudar com seu c√≥digo?

        Para que eu possa te ajudar melhor, voc√™ pode me pedir explicitamente para usar algumas ferramentas:

        - Se quiser que eu consulte c√≥digos, arquivos ou documentos espec√≠ficos do projeto, solicite diretamente que eu utilize a ferramenta `retriever_tool`. Exemplos:
          - "Use a retriever_tool para consultar o arquivo settings.py do Django"
          - "Busque no retriever_tool como foi feita a autentica√ß√£o JWT no projeto React"

        - Caso precise que eu valide ideias, execute testes r√°pidos ou rode trechos de c√≥digo Python, solicite o uso da ferramenta `python_repl`. Exemplos:
          - "Execute com python_repl uma fun√ß√£o que valida esse regex"
          - "Use python_repl para testar rapidamente este trecho de c√≥digo"

        - Para buscas atualizadas diretamente da internet, como documenta√ß√µes, corre√ß√µes de bugs ou exemplos externos, solicite o uso da ferramenta `brave_tool`. Exemplos:
          - "Use brave_tool para consultar a documenta√ß√£o mais recente do Django REST Framework"
          - "Consulte com brave_tool exemplos recentes de implementa√ß√£o do Zustand no React"

        - Caso precise buscar solu√ß√µes t√©cnicas comuns, exemplos pr√°ticos ou d√∫vidas respondidas pela comunidade, pe√ßa que eu utilize a ferramenta `stackexchange_tool`. Exemplos:
          - "Busque com stackexchange_tool como resolver esse erro do Docker"
          - "Use stackexchange_tool para encontrar exemplos de queries complexas no Django ORM"

        Lembre-se de solicitar explicitamente as ferramentas, pois n√£o consigo acion√°-las automaticamente!

        Estou aqui pra te ajudar com clareza e de forma amig√°vel! üòâ
        """,
        }
    ]


def render_message(content):
    if "<think>" in content:
        prefix, _, rest = content.partition("<think>")
        think_content, _, suffix = rest.partition("</think>")
        if prefix.strip():
            st.markdown(prefix.strip())
        with st.expander("Detalhes üß†"):
            st.info(think_content.strip())
        if suffix.strip():
            st.markdown(suffix.strip())
    else:
        st.markdown(content)


for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        render_message(msg["content"])

if question := st.chat_input("Digite sua pergunta sobre o c√≥digo"):
    st.session_state.chat_history.append({"role": "user", "content": question})
    with st.chat_message("user"):
        render_message(question)

    with st.chat_message("assistant"):
        with st.spinner("Pensando..."):
            response = agent_executor.invoke({"input": question}).get(
                "output", "N√£o consegui processar sua pergunta."
            )
            render_message(response)
            st.session_state.chat_history.append(
                {"role": "assistant", "content": response}
            )
